{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qizhu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import os\n",
    "import pickle  # for storing the model\n",
    "import timeit  # for tracking how much time used\n",
    "from datetime import date, datetime   # Get the date of the day\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing all the package, let's get started! \n",
    "First start a random seed - which helps with Reproducibility, keep Consistency Across Runs for easier testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the query for sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here starts the data loader for pytorch model - multiple instance binary classification\n",
    "# For more info: https://github.com/jakubmonhart/mil_pytorch/blob/master/README.md\n",
    "class BagModel(nn.Module):\n",
    "    \"\"\"\n",
    "      Model for solving MIL problems\n",
    "    \n",
    "      Args:\n",
    "        prepNN: neural network created by user processing input before aggregation function (subclass of torch.nn.Module)\n",
    "        afterNN: neural network created by user processing output of aggregation function and outputing final output of BagModel (subclass of torch.nn.Module)\n",
    "        aggregation_func: mil.max and mil.mean supported, any aggregation function with argument dim and same behaviour as torch.mean can be used\n",
    "    \n",
    "      Returns:\n",
    "        Output of forward function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prepNN, afterNN, aggregation_func):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.prepNN = prepNN\n",
    "        self.aggregation_func = aggregation_func\n",
    "        self.afterNN = afterNN\n",
    "      \n",
    "    def forward(self, input):  \n",
    "        \n",
    "        ids = input[1]\n",
    "        input = input[0]\n",
    "        input = input.to(torch.float32)\n",
    "        # Modify shape of bagids if only 1d tensor\n",
    "        if (len(ids.shape) == 1):\n",
    "          ids.resize_(1, len(ids))\n",
    "    \n",
    "        inner_ids = ids[len(ids)-1]\n",
    "    \n",
    "        device = input.device\n",
    "    \n",
    "        NN_out = self.prepNN(input)\n",
    "          \n",
    "        unique, inverse, counts = torch.unique(inner_ids, sorted = True, return_inverse = True, return_counts = True)\n",
    "        idx = torch.cat([(inverse == x).nonzero()[0] for x in range(len(unique))]).sort()[1]\n",
    "        bags = unique[idx]\n",
    "        counts = counts[idx]\n",
    "    \n",
    "        output = torch.empty((len(bags), len(NN_out[0])), device = device)\n",
    "    \n",
    "        for i, bag in enumerate(bags):\n",
    "          output[i] = self.aggregation_func(NN_out[inner_ids == bag], dim = 0)\n",
    "        \n",
    "        output = self.afterNN(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        if (ids.shape[0] == 1):\n",
    "          return output\n",
    "        else:\n",
    "          ids = ids[:len(ids)-1]\n",
    "          mask = torch.empty(0, device = device).long()\n",
    "          for i in range(len(counts)):\n",
    "            mask = torch.cat((mask, torch.sum(counts[:i], dtype = torch.int64).reshape(1)))\n",
    "          return (output, ids[:,mask])\n",
    "\n",
    "\n",
    "class MilDataset(Dataset):\n",
    "    \"\"\"\n",
    "      Subclass of torch.utils.data.Dataset. \n",
    "    \n",
    "      Args:\n",
    "        data:\n",
    "        ids:\n",
    "        labels:\n",
    "        normalize:\n",
    "    \"\"\"\n",
    "    def __init__(self, data, ids, labels, normalize=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "    \n",
    "        # Modify shape of bagids if only 1d tensor\n",
    "        if (len(ids.shape) == 1):\n",
    "          ids.resize_(1, len(ids))\n",
    "      \n",
    "        self.bags = torch.unique(self.ids[0])\n",
    "      \n",
    "        # Normalize\n",
    "        if normalize:\n",
    "          std = self.data.std(dim=0)\n",
    "          mean = self.data.mean(dim=0)\n",
    "          self.data = (self.data - mean)/std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bags)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[self.ids[0] == self.bags[index]]\n",
    "        bagids = self.ids[:, self.ids[0] == self.bags[index]]\n",
    "        labels = self.labels[index]\n",
    "    \n",
    "        return data, bagids, labels\n",
    "      \n",
    "    def n_features(self):\n",
    "        return self.data.size(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Target encoder.\n",
    "    \n",
    "    Replaces categorical column(s) with the mean target value for\n",
    "    each category.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cols=None):\n",
    "        \"\"\"Target encoder\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cols : list of str\n",
    "            Columns to target encode.  Default is to target \n",
    "            encode all categorical columns in the DataFrame.\n",
    "        \"\"\"\n",
    "        if isinstance(cols, str):\n",
    "            self.cols = [cols]\n",
    "        else:\n",
    "            self.cols = cols\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = X.fillna(0)\n",
    "        \"\"\"Fit target encoder to X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode all categorical cols by default\n",
    "        if self.cols is None:\n",
    "            self.cols = [col for col in X \n",
    "                         if str(X[col].dtype)=='object']\n",
    "\n",
    "        # Check columns are in X\n",
    "        for col in self.cols:\n",
    "            if col not in X:\n",
    "                raise ValueError(f\"Column '{col}' not found in X.\")\n",
    "\n",
    "        # Encode each element of each column\n",
    "        self.maps = dict() #dict to store map for each column\n",
    "        for col in self.cols:\n",
    "            tmap = dict()\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                tmap[unique] = y[X[col]==unique].mean()    # Use the mean value of the conversion rate\n",
    "            self.maps[col] = tmap\n",
    "            \n",
    "        return self\n",
    "\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Perform the target encoding transformation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        Xo = X.copy()\n",
    "        for col, tmap in self.maps.items():\n",
    "            # Initialize an array of nan values \n",
    "            vals = np.full(X.shape[0], np.nan)\n",
    "            for val, mean_target in tmap.items():\n",
    "                vals[X[col]==val] = mean_target\n",
    "            Xo[col] = vals\n",
    "        \n",
    "        return Xo\n",
    "            \n",
    "            \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform the data via target encoding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values (required!).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        #X = X.fillna(0)\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n",
    "\n",
    "# Leave one out target encoder is an advanced target encoder\n",
    "# It make sure there is less data leakage\n",
    "\n",
    "class TargetEncoderLOO(TargetEncoder):\n",
    "    \"\"\"Leave-one-out target encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cols=None):\n",
    "        \"\"\"Leave-one-out target encoding for categorical features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cols : list of str\n",
    "            Columns to target encode.\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit leave-one-out target encoder to X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to target encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode all categorical cols by default\n",
    "        if self.cols is None:\n",
    "            self.cols = [col for col in X\n",
    "                         if str(X[col].dtype)=='object']\n",
    "\n",
    "        # Check columns are in X\n",
    "        for col in self.cols:\n",
    "            if col not in X:\n",
    "                raise ValueError(f\"Column '{col}' not found in X.\") \n",
    "\n",
    "        # Encode each element of each column\n",
    "        self.sum_count = dict()\n",
    "        for col in self.cols:\n",
    "            self.sum_count[col] = dict()\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                ix = X[col]==unique\n",
    "                self.sum_count[col][unique] = \\\n",
    "                    (y[ix].sum(),ix.sum())\n",
    "            \n",
    "        # Return the fit object\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Perform the target encoding transformation.\n",
    "\n",
    "        Uses leave-one-out target encoding for the training fold,\n",
    "        and uses normal target encoding for the test fold.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create output dataframe\n",
    "        Xo = X.copy()\n",
    "\n",
    "        # Use normal target encoding if this is test data\n",
    "        if y is None:\n",
    "            for col in self.sum_count:\n",
    "                vals = np.full(X.shape[0], np.nan)\n",
    "                for cat, sum_count in self.sum_count[col].items():\n",
    "                    vals[X[col]==cat] = sum_count[0]/sum_count[1]\n",
    "                Xo[col] = vals\n",
    "\n",
    "        # LOO target encode each column\n",
    "        else:\n",
    "            for col in self.sum_count:\n",
    "                vals = np.full(X.shape[0], np.nan)\n",
    "                for cat, sum_count in self.sum_count[col].items():\n",
    "                    ix = X[col]==cat\n",
    "                    vals[ix] = (sum_count[0]-y[ix])/(sum_count[1]-1)\n",
    "                Xo[col] = vals\n",
    "            \n",
    "        # Return encoded DataFrame\n",
    "        Xo = Xo.fillna(0)\n",
    "        return Xo\n",
    "      \n",
    "            \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform the data via target encoding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values (required!).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        X = X.fillna(0)\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here starts the main function for lookalike model\n",
    "\n",
    "class LOOKALIKE_MODEL:\n",
    "    def __init__(self, training_ratio, model_training, if_store_model, model_prediction, AUDIENCE_LIMIT, n_neurons,lr, n_epochs, batch_size,weight_decay):\n",
    "        # Basic Setting\n",
    "        self.training_ratio = training_ratio\n",
    "        self.training_ratio_r = training_ratio +1\n",
    "        self.model_training = model_training\n",
    "        self.if_store_model = if_store_model\n",
    "        self.model_prediction = model_prediction\n",
    "        self.model_path = '/LookAlikeModel.pth'\n",
    "\n",
    "        \n",
    "        # Model setting\n",
    "        self.n_neurons = n_neurons\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay \n",
    "        self.pos_weight = torch.tensor([self.training_ratio_r])\n",
    "\n",
    "        \n",
    "        \n",
    "        # File setting\n",
    "        self.data_sample_address = \"Data_sample.csv\"\n",
    "        self.result_file_address = \"/\"\n",
    "\n",
    "        # os.mkdir(self.result_file_address)\n",
    "\n",
    "\n",
    "\n",
    "        self.AUDIENCE_LIMIT = AUDIENCE_LIMIT\n",
    "        # Tools\n",
    "        self.te = TargetEncoderLOO()\n",
    "\n",
    "        # Create the /tmp/model directory if it doesnt exist\n",
    "        os.makedirs('/tmp/model', exist_ok=True)\n",
    "\n",
    "    # function for MIL\n",
    "    def collate(self, batch):\n",
    "        \"\"\"\n",
    "        Collate function for MIL.\n",
    "        \"\"\"\n",
    "        batch_data = []\n",
    "        batch_bagids = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            batch_data.append(sample[0])\n",
    "            batch_bagids.append(sample[1])\n",
    "            batch_labels.append(sample[2])\n",
    "\n",
    "        out_data = torch.cat(batch_data, dim=0)\n",
    "        out_bagids = torch.cat(batch_bagids, dim=1)\n",
    "        out_labels = torch.stack(batch_labels)\n",
    "\n",
    "        return out_data, out_bagids, out_labels\n",
    "\n",
    "    def collate_np(self, batch):\n",
    "        \"\"\"\n",
    "        Collate function for numpy.\n",
    "        \"\"\"\n",
    "        batch_data = []\n",
    "        batch_bagids = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            batch_data.append(sample[0])\n",
    "            batch_bagids.append(sample[1])\n",
    "            batch_labels.append(sample[2])\n",
    "\n",
    "        out_data = torch.cat(batch_data, dim=0)\n",
    "        out_bagids = torch.cat(batch_bagids, dim=1)\n",
    "        out_labels = torch.tensor(batch_labels)\n",
    "\n",
    "        return out_data, out_bagids, out_labels\n",
    "\n",
    "    def prepare_modelling_data(self):\n",
    "\n",
    "        print(\"\\n ---------- Start preparing modelling data ---------------\")\n",
    "        self.training_data = pd.read_csv(self.data_sample_address)\n",
    "        # Read the CSV file\n",
    "\n",
    "        # Display the first few rows of the dataframe\n",
    "        print(self.training_data.head())\n",
    "\n",
    "        # Count the number of rows where 'conversion' is equal to 1\n",
    "        conv_1 = self.training_data[self.training_data['CONVERSION'] == 1].head(self.AUDIENCE_LIMIT // self.training_ratio_r)\n",
    "        non_conv = self.training_data[self.training_data['CONVERSION'] != 1].head(self.AUDIENCE_LIMIT - self.AUDIENCE_LIMIT // self.training_ratio_r)\n",
    "\n",
    "        # Combine the two sets of rows\n",
    "        self.training_data = pd.concat([conv_1, non_conv])\n",
    "        conversion_count = (self.training_data['CONVERSION'] == 1).sum()\n",
    "\n",
    "        print(f\"\\nNumber of conversions: {conversion_count}\")\n",
    "        print(f\"\\nNumber of nonconversions: {self.training_data['CONVERSION'].count() - conversion_count}\")\n",
    "        print(f\"\\nConversion Ratio: {conversion_count / self.training_data['CONVERSION'].count()}\")\n",
    "        print(f\"\\nAdjust based on training ratio: {self.training_ratio} and modeling limit: {self.AUDIENCE_LIMIT}.\")\n",
    "\n",
    "\n",
    "    def process_lookalike_model_data(self, data):\n",
    "        print(\"\\n -------------------------\")\n",
    "\n",
    "        data.fillna(0)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        # Step 1: Extract the labels, features, and IDs for PyTorch\n",
    "        if \"CONVERSION\" in data.columns:\n",
    "            y = data[\"CONVERSION\"].values\n",
    "            X = data.iloc[:, 1:]  # Features start from the second column\n",
    "            print(\"\\n--------- Training Data Information ----------\\n\")\n",
    "\n",
    "            print(f\"Number of converts is {np.sum(y == 1)}.\\n\")\n",
    "\n",
    "            print(f\"Number of non-converts is {np.sum(y == 0)}.\\n\")\n",
    "\n",
    "            print(f\"Total number of data is {len(data)}.\\n\")\n",
    "\n",
    "            # Apply target encoding\n",
    "            X_encoded_loo = self.te.fit_transform(X, y)\n",
    "            print(f\"\\nTraining Data set:\")\n",
    "\n",
    "            print(f\"\\n{X.head()}\")\n",
    "\n",
    "            print(f\"\\n--------------------------\")\n",
    "\n",
    "            print(f\"\\n{X_encoded_loo.head()}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n--------- Prediction Data Information ----------\\n\")\n",
    "            print(f\"Total number of data is {len(data)}.\\n\")\n",
    "\n",
    "            X = data.iloc[:, :]  # Features start from the first column\n",
    "            y = torch.zeros(len(data), dtype=torch.float32)\n",
    "            X_encoded_loo = self.te.transform(X)\n",
    "\n",
    "            print(f\"\\nPrediction Data set:\")\n",
    "\n",
    "            print(f\"\\n{X.head()}\")\n",
    "\n",
    "            print(f\"\\n--------------------------\")\n",
    "\n",
    "            print(f\"\\n{X_encoded_loo.head()}\")\n",
    "\n",
    "            print(f\"\\n{X_encoded_loo.head().iloc[:, 1:]}\")\n",
    "\n",
    "            print(f\"\\n{X_encoded_loo.iloc[:, 1:]}\")\n",
    "\n",
    "        # Step 2: Convert encoded features and IDs to tensors\n",
    "        data_tensor = torch.tensor(X_encoded_loo.astype(float).iloc[:, 1:].values, dtype=torch.float32)\n",
    "        ids_tensor = torch.tensor(X_encoded_loo[\"MODEL_ID\"].values, dtype=torch.float32)\n",
    "\n",
    "        #print(f\"\\nTraining Data set:\")\n",
    "\n",
    "        #print(f\"\\n{data_tensor[:5]}\")\n",
    "\n",
    "        self.training_features = X_encoded_loo.columns[1:]\n",
    "        # Store data, labels, and ids\n",
    "        data = data_tensor\n",
    "        instance_labels = torch.tensor(y, dtype=torch.float32)\n",
    "        ids = ids_tensor\n",
    "\n",
    "        # Step 3: Create bag labels from instance labels\n",
    "        bagids = torch.unique(ids)\n",
    "        labels = torch.stack([torch.max(instance_labels[ids == i]) for i in bagids]).float()\n",
    "        print(f\"\\n INFO: Data shape \\n  data: {data.shape}\\n  ids: {ids.shape}\\n  labels: {labels.shape}\")\n",
    "\n",
    "        # Step 4: Create dataset\n",
    "        dataset = MilDataset(data, ids, labels, normalize=True)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def loading_data_to_dataloader(self, dataframe, if_training_data=True):\n",
    "        # This function is to call modify data structure\n",
    "        # First call target encoder to turn non-numeric data to numeric\n",
    "        # Then load the LookAlikeModel_DataLoader to modify the data structure suitable for Pytorch\n",
    "\n",
    "        result_data = self.process_lookalike_model_data(dataframe)\n",
    "\n",
    "        if if_training_data == True:\n",
    "            train_indices, test_indices = train_test_split(np.arange(len(result_data)), test_size=0.2, stratify=result_data.labels)\n",
    "            train, test = Subset(result_data, train_indices), Subset(result_data, test_indices)\n",
    "            train_dl, test_dl = DataLoader(train, batch_size=self.batch_size, collate_fn=self.collate, drop_last=True), DataLoader(test, batch_size=self.batch_size, collate_fn=self.collate, drop_last=True)\n",
    "            return train_dl, test_dl\n",
    "        else:\n",
    "            # Testing\n",
    "            return result_data\n",
    "            result_dl = DataLoader(result_data, batch_size=self.batch_size, collate_fn=self.collate, drop_last=True)\n",
    "            return response, result_dl\n",
    "\n",
    "    def LookAlikeModel_train(self):\n",
    "       \n",
    "        print(\"\\n----- Deep Learn Model Training Starts -----\")\n",
    "\n",
    "        # This is the main Deep Learn Model\n",
    "\n",
    "        # Step 1: Define the model\n",
    "        prepNN = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.feature_number, self.n_neurons),\n",
    "            #torch.nn.ReLU()\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        afterNN = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.n_neurons, 1)\n",
    "        )\n",
    "\n",
    "        # Define model, loss function, and optimizer\n",
    "        self.LookAlikemodel = BagModel(prepNN, afterNN, torch.mean)  \n",
    "\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)  # loss function \n",
    "        optimizer = torch.optim.Adam(self.LookAlikemodel.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        #criterion = nn.BCEWithLogitsLoss()\n",
    "        #optimizer = torch.optim.Adam(self.LookAlikemodel.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "\n",
    "        # Step 2: Train the model\n",
    "        losses = []\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for t in range(self.n_epochs):\n",
    "            for data, bagids, labels in self.training_data:\n",
    "                pred = self.LookAlikemodel((data, bagids)).squeeze()\n",
    "                loss = criterion(pred, labels)\n",
    "\n",
    "                # Optimizer step\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Log\n",
    "            losses.append(running_loss / len(self.training_data))\n",
    "            running_loss = 0.0\n",
    "            if (t + 1) % 10 == 0:\n",
    "                print(\"\\nepoch: {} | loss: {:.3f}\".format(t + 1, sum(losses[-10:]) / 10))\n",
    "\n",
    "        # Step 3: Model testing - on Training set\n",
    "        print(\"\\nTesting starts here.......\")\n",
    "\n",
    "        print(self.check_model_accuracy(self.training_data, \"Training Data\"))\n",
    "\n",
    "        # Step 4: Model testing - on Testing set\n",
    "\n",
    "        print(self.check_model_accuracy(self.testing_data, \"Testing Data\"))\n",
    "\n",
    "        print(\"\\nTesting ends here.......\")\n",
    "\n",
    "        # Step 5: Store the Model\n",
    "        if self.if_store_model == True:\n",
    "            self.store_model()\n",
    "\n",
    "\n",
    "\n",
    "    def explain_with_shap(self, data, predictions):\n",
    "        # This part of code needs modifications\n",
    "        if isinstance(data, list):\n",
    "            data = np.array(data)\n",
    "        if isinstance(predictions, list):\n",
    "            predictions = np.array(predictions)\n",
    "\n",
    "        def predict_function(data_array):\n",
    "            # Return the corresponding precomputed predictions for each row in data_array\n",
    "            return predictions[:data_array.shape[0]]\n",
    "\n",
    "        explainer = shap.KernelExplainer(predict_function, data)\n",
    "        shap_values = explainer.shap_values(data)\n",
    "        shap.summary_plot(shap_values, data, plot_type=\"bar\")\n",
    "        plt.show()\n",
    "\n",
    "    def check_model_accuracy(self, data_batch, data_name):\n",
    "        # This function is to check model accuracy\n",
    "        print(f\"\\n Model testing on {data_name}\")\n",
    "\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_data = []\n",
    "        try:\n",
    "            for data, bagids, labels in data_batch:\n",
    "                pred = self.LookAlikemodel((data, bagids)).squeeze() > 0.5\n",
    "                correct_count += (pred == labels).sum()\n",
    "                total_count += len(labels)\n",
    "                all_preds.extend(pred.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            data_conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "            print(\"\\nAccuracy: {:.1f} %\".format((correct_count / total_count) * 100))\n",
    "\n",
    "            print(f\"\\nConfusion Matrix:\\n{data_conf_matrix}\")\n",
    "\n",
    "            # For model storage\n",
    "            # Convert tensors to DataFrames with extracted column names\n",
    "            print(\"\\nTesting area for sample input data\")\n",
    "\n",
    "            print(f\"\\nData shape: {data.shape}\") # Should be (num_samples, num_features)\n",
    "\n",
    "            print(f\"\\nNumber of training features: {len(self.training_features)}\")\n",
    "\n",
    "            print(f\"\\nBagids shape: {bagids.shape}\") # Should be (num_samples, 1)\n",
    "\n",
    "            print(f\"\\nConstruct data_df\")\n",
    "\n",
    "            data_df = pd.DataFrame(data.numpy(), columns=self.training_features)\n",
    "            print(f\"\\nConstruct bagids_df\")\n",
    "\n",
    "            bagids_df = pd.DataFrame(bagids.numpy()[0], columns=[\"MODEL_ID\"])\n",
    "            print(f\"\\nbagids_df shape is {bagids_df.shape}.\\ndata_df shape is {data_df.shape}.\\nbagids_df column is {bagids_df.columns}.\\ndata_df column is {data_df.columns}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n->Simple Error: {str(e)}\")\n",
    "\n",
    "        try:\n",
    "            # Combine data and bagids into a single DataFrame\n",
    "            print(\"\\n---------------a--------------------\")\n",
    "\n",
    "            data = {\n",
    "                \"data\": [[torch.tensor([-0.5596, -0.1165, 0.8])], [torch.tensor([1671705., 2393908.])]],\n",
    "                \"bagids\": [[torch.tensor([1, 2, 3])], [torch.tensor([4, 5])]]\n",
    "            }\n",
    "\n",
    "            print(\"\\n---------------d--------------------\")\n",
    "\n",
    "            #response += f\"\\nSample Input Data shape is {self.sample_input_data.shape}.\\nSample Input Data column is {self.sample_input_data.columns}.\"\n",
    "            #print(f\"\\nSample Input Data shape is {self.sample_input_data.shape}.\\nSample Input Data column is {self.sample_input_data.columns}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n->Concat Sample_input_data Error: {str(e)}\")\n",
    "\n",
    "        try:\n",
    "            self.explain_with_shap(all_data, all_preds)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n->Explain_with_shap Error: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "    def store_model(self):\n",
    "        # This function is to save the pytorch model \n",
    "        # Get database info\n",
    "        print('\\n--------Model Storage Starts--------------')\n",
    "\n",
    "        try:\n",
    "\n",
    "            torch.save(self.LookAlikemodel.state_dict(), self.model_path)\n",
    "            print('\\n--------Step 1 Complete--------------')\n",
    "\n",
    "\n",
    "     \n",
    "            \n",
    "\n",
    "            ####################################################\n",
    "            ## Write code here to store model for prediction ###\n",
    "            ####################################################\n",
    "           \n",
    "            print('\\n--------Step 2 Complete--------------')\n",
    "            #print(f\"\\nLookAlikeModel_{self.data_id} successful stored\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"\\n\"+ str(e))\n",
    "\n",
    "\n",
    "\n",
    "    def prediction(self, AUDIENCE_LIMIT):\n",
    "        print(\"\\nStart loading audience for prediction.\")\n",
    "        ####################################################\n",
    "        ## Write code here to prepare data for prediction ##\n",
    "        ####################################################\n",
    "        \n",
    "    \n",
    "        prediction_data_dl = self.loading_data_to_dataloader(prediction_data, False)\n",
    "\n",
    "\n",
    "        print(\"\\nStart audience prediction\")\n",
    "\n",
    "        batch_data = []\n",
    "        try:\n",
    "            first_batch = next(iter(prediction_data_dl))\n",
    "            print(f\"\\nSample data from prediction DataLoader: {first_batch}\")\n",
    "            # Unpack the first batch\n",
    "            data, bagids, labels = first_batch\n",
    "            \n",
    "            # Add the data to the response\n",
    "\n",
    "            print(f\"\\nFirst Row of Prediction Data: \\nFeatures: {data}\\nBag IDs: {bagids}\\nLabels: {labels}\\n\")\n",
    "            self.feature_number = len(data[0])\n",
    "   \n",
    "            print(f\"\\nFeature number: {self.feature_number}\")\n",
    "        except StopIteration:\n",
    "\n",
    "            print(\"\\nPrediction DataLoader is empty. Move on the the next step\")\n",
    "        \n",
    "        self.LookAlikemodel.eval()\n",
    "        with torch.no_grad():\n",
    "            current_timestamp =  datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            len_loaded = 0\n",
    "            len_not_loaded = 0\n",
    "            for data, bagids, labels in prediction_data_dl:\n",
    "                pred = self.LookAlikemodel((data, bagids)).squeeze()\n",
    "                try:\n",
    "                    batch_data.append((self.data_id, int(bagids.flatten()[0].item()), pred.item(),current_timestamp ,f\"v_{date.today()}\".replace(\"-\", \"_\")))\n",
    "                    len_loaded += 1\n",
    "                except Exception as e:\n",
    "                    len_not_loaded += 1\n",
    "             \n",
    "                    print(f\"\\nError appending to batch_data: {str(e)}\")\n",
    "         \n",
    "                    print(f\"\\nPrediction: {str(pred.item())}\")\n",
    "                    # Handle the case where bagids contains more than one element\n",
    "                    if bagids.numel() == 1:\n",
    "                        print(f\"\\nBag ID: {str(bagids.item())}\")\n",
    "                    else:\n",
    "                        print(f\"\\nBag IDs: {str(bagids.tolist())}\")\n",
    "        \n",
    "        print(f\"\\nLoaded data:{len_loaded}.\\nNot loaded data:{len_not_loaded}.\")\n",
    "        # Write batch_data to SQL table\n",
    "        prediction_df = pd.DataFrame(batch_data, columns=[ \"ADVERTISER_ID\", \"MODEL_ID\", \"PREDICTION\", \"TIMESTAMP\", \"MODEL_VERSION\"])\n",
    "        print(f\"\\nExample of prediction.\")\n",
    "        print(f\"\\n{prediction_df.head()}\")\n",
    "        #result_df = self.session.sql(q)  \n",
    "        # Store the result in the specified table\n",
    "        # prediction_df.write.mode(\"ignore\").saveAsTable(\"LOOKALIKE_AUDIENCE_PREDICTION\")\n",
    "        try:\n",
    "            print('Write code here to store results as CSV')\n",
    "            #success, nchunks, nrows, _ = write_pandas(self.session, prediction_df, \"LOOKALIKE_AUDIENCE_PREDICTION\")\n",
    "        \n",
    "            ####################################################\n",
    "            ##### Write code here to store results as CSV ######\n",
    "            ####################################################\n",
    "        except Exception as e:\n",
    "    \n",
    "            print(str(e))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def main(self):\n",
    "\n",
    "        print(\"\\n LookAlike Model Session Start\\n -----------------------------\\n \")\n",
    "        #response += FeatureSpec.__init__.__doc__\n",
    "   \n",
    "        try:\n",
    "\n",
    "            \n",
    "            if self.model_training == True:\n",
    "                \n",
    "\n",
    "                self.prepare_modelling_data()\n",
    "              \n",
    "                print(\"\\nModeling Dataset Ready\")\n",
    "\n",
    "                if (self.training_data['CONVERSION'] == 1).sum() > 0:\n",
    "            \n",
    "                    print(\"\\nUse Lookalike Dataloader to mofidy data structure.\")\n",
    "                    if self.model_training == True:\n",
    "                        self.training_data, self.testing_data = self.loading_data_to_dataloader(self.training_data, True)\n",
    "                    #else:\n",
    "                    #    response_dl, self.prediction_data = self.loading_data_to_dataloader(self.training_data, False)\n",
    "                    # Checking the dataset\n",
    "    \n",
    "                    try:\n",
    "                        first_batch = next(iter(self.testing_data))\n",
    "            \n",
    "                        print(f\"\\nSample data from train DataLoader: {first_batch}\")\n",
    "                        # Unpack the first batch\n",
    "                        data, bagids, labels = first_batch\n",
    "                        \n",
    "                        # Add the data to the response\n",
    "                        print(f\"\\nFirst Row of Data: \\nFeatures: {data}\\nBag IDs: {bagids}\\nLabels: {labels}\\n\")\n",
    "                        self.feature_number = len(data[0])\n",
    "                     \n",
    "                        print(f\"\\nFeature number: {self.feature_number}\")\n",
    "                    except StopIteration:\n",
    "    \n",
    "                        print(\"\\nTrain DataLoader is empty. Move on the the next step\")\n",
    "                    \n",
    "                    print(\"\\n-------Model Training Starts -------\")\n",
    "                    start_time = time.time()\n",
    "                    self.LookAlikeModel_train()\n",
    "                    end_time = time.time()\n",
    "                    print(f\"\\nRun time for training model is: {end_time - start_time} seconds\")\n",
    "\n",
    "                    print(\"\\n-------Model Training Ends -------\")\n",
    "    \n",
    "                else:\n",
    "                \n",
    "                    print(\"\\n Need more info to prepare modelling data.\")\n",
    "\n",
    "           \n",
    "                \n",
    "            if self.model_prediction == True:\n",
    "                start_time = time.time()\n",
    "                self.prediction(self.AUDIENCE_LIMIT)    \n",
    "                end_time = time.time()\n",
    "\n",
    "                print(f\"\\nRun time for prediction is: {end_time - start_time} seconds\")\n",
    "            \n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"\\Error: {str(e)}\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LookAlike Model Session Start\n",
      " -----------------------------\n",
      " \n",
      "\n",
      " ---------- Start preparing modelling data ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qizhu\\AppData\\Local\\Temp\\ipykernel_67516\\456656115.py:81: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.training_data = pd.read_csv(self.data_sample_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CONVERSION  MODEL_ID ADVERTISER_ID  TOTAL_CLICK        DEVICE BROWSER  \\\n",
      "0           1   1684633          1184           46  AndriodPhone  Chrome   \n",
      "1           1   3768237          1184            9         Linux  Chrome   \n",
      "2           1   4063696          1184           15         MacPC  Chrome   \n",
      "3           1   1517264          1184            6  AndriodPhone  Chrome   \n",
      "4           1   2014401          1184            7         Linux  Chrome   \n",
      "\n",
      "   UNIQUE_SESSION_NUM  UNIQUE_DAYS  TOTAL_TIME_ONSITE  TOTAL_SPEND  ...  \\\n",
      "0                 6.0            4             5388.0        316.0  ...   \n",
      "1                 1.0            1              243.0        504.0  ...   \n",
      "2                 2.0            1             5087.0         55.0  ...   \n",
      "3                 1.0            1              833.0        150.0  ...   \n",
      "4                 1.0            1              195.0        202.0  ...   \n",
      "\n",
      "   TUESDAYVISIT WEDNESDAYVISIT THURSDAYVISIT FRIDAYVISIT  SATURDAYVISIT  \\\n",
      "0            10              0            16           6             14   \n",
      "1             0              0             0           9              0   \n",
      "2             0             15             0           0              0   \n",
      "3             0              0             0           0              0   \n",
      "4             0              7             0           0              0   \n",
      "\n",
      "   SUNDAYVISIT  MORNINGVISIT  DAYVISIT  EVENINGVISIT  NIGHTVISIT  \n",
      "0            0            16         6            24           0  \n",
      "1            0             0         9             0           0  \n",
      "2            0             0         0            15           0  \n",
      "3            6             0         6             0           0  \n",
      "4            0             0         7             0           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Number of conversions: 333\n",
      "\n",
      "Number of nonconversions: 667\n",
      "\n",
      "Conversion Ratio: 0.333\n",
      "\n",
      "Adjust based on training ratio: 2 and modeling limit: 1000.\n",
      "\n",
      "Modeling Dataset Ready\n",
      "\n",
      "Use Lookalike Dataloader to mofidy data structure.\n",
      "\n",
      " -------------------------\n",
      "\n",
      "--------- Training Data Information ----------\n",
      "\n",
      "Number of converts is 333.\n",
      "\n",
      "Number of non-converts is 667.\n",
      "\n",
      "Total number of data is 1000.\n",
      "\n",
      "\n",
      "Training Data set:\n",
      "\n",
      "   MODEL_ID ADVERTISER_ID  TOTAL_CLICK        DEVICE BROWSER  \\\n",
      "0   1684633          1184           46  AndriodPhone  Chrome   \n",
      "1   3768237          1184            9         Linux  Chrome   \n",
      "2   4063696          1184           15         MacPC  Chrome   \n",
      "3   1517264          1184            6  AndriodPhone  Chrome   \n",
      "4   2014401          1184            7         Linux  Chrome   \n",
      "\n",
      "   UNIQUE_SESSION_NUM  UNIQUE_DAYS  TOTAL_TIME_ONSITE  TOTAL_SPEND  \\\n",
      "0                 6.0            4             5388.0        316.0   \n",
      "1                 1.0            1              243.0        504.0   \n",
      "2                 2.0            1             5087.0         55.0   \n",
      "3                 1.0            1              833.0        150.0   \n",
      "4                 1.0            1              195.0        202.0   \n",
      "\n",
      "   AVG_SESSION_DURATION REFERRAL_SOURCE SITE_INTERACTION  \\\n",
      "0            149.666667      [\\n  \"\"\\n]       [\\n  \"\"\\n]   \n",
      "1             30.375000      [\\n  \"\"\\n]       [\\n  \"\"\\n]   \n",
      "2            391.307692      [\\n  \"\"\\n]       [\\n  \"\"\\n]   \n",
      "3            166.600000      [\\n  \"\"\\n]       [\\n  \"\"\\n]   \n",
      "4             32.500000      [\\n  \"\"\\n]       [\\n  \"\"\\n]   \n",
      "\n",
      "               REFERRAL_SITE  MONDAYVISIT  TUESDAYVISIT  WEDNESDAYVISIT  \\\n",
      "0  [\\n  \"www.news.com.au\"\\n]            0            10               0   \n",
      "1                         []            0             0               0   \n",
      "2                         []            0             0              15   \n",
      "3                         []            0             0               0   \n",
      "4                         []            0             0               7   \n",
      "\n",
      "   THURSDAYVISIT  FRIDAYVISIT  SATURDAYVISIT  SUNDAYVISIT  MORNINGVISIT  \\\n",
      "0             16            6             14            0            16   \n",
      "1              0            9              0            0             0   \n",
      "2              0            0              0            0             0   \n",
      "3              0            0              0            6             0   \n",
      "4              0            0              0            0             0   \n",
      "\n",
      "   DAYVISIT  EVENINGVISIT  NIGHTVISIT  \n",
      "0         6            24           0  \n",
      "1         9             0           0  \n",
      "2         0            15           0  \n",
      "3         6             0           0  \n",
      "4         7             0           0  \n",
      "\n",
      "--------------------------\n",
      "\n",
      "   MODEL_ID  ADVERTISER_ID  TOTAL_CLICK    DEVICE   BROWSER  \\\n",
      "0   1684633           1184           46  0.248244  0.381068   \n",
      "1   3768237           1184            9  0.685714  0.381068   \n",
      "2   4063696           1184           15  0.481481  0.381068   \n",
      "3   1517264           1184            6  0.248244  0.381068   \n",
      "4   2014401           1184            7  0.685714  0.381068   \n",
      "\n",
      "   UNIQUE_SESSION_NUM  UNIQUE_DAYS  TOTAL_TIME_ONSITE  TOTAL_SPEND  \\\n",
      "0                 6.0            4             5388.0        316.0   \n",
      "1                 1.0            1              243.0        504.0   \n",
      "2                 2.0            1             5087.0         55.0   \n",
      "3                 1.0            1              833.0        150.0   \n",
      "4                 1.0            1              195.0        202.0   \n",
      "\n",
      "   AVG_SESSION_DURATION  REFERRAL_SOURCE  SITE_INTERACTION  REFERRAL_SITE  \\\n",
      "0            149.666667          0.34962          0.333333       0.333333   \n",
      "1             30.375000          0.34962          0.333333       0.369883   \n",
      "2            391.307692          0.34962          0.333333       0.369883   \n",
      "3            166.600000          0.34962          0.333333       0.369883   \n",
      "4             32.500000          0.34962          0.333333       0.369883   \n",
      "\n",
      "   MONDAYVISIT  TUESDAYVISIT  WEDNESDAYVISIT  THURSDAYVISIT  FRIDAYVISIT  \\\n",
      "0            0            10               0             16            6   \n",
      "1            0             0               0              0            9   \n",
      "2            0             0              15              0            0   \n",
      "3            0             0               0              0            0   \n",
      "4            0             0               7              0            0   \n",
      "\n",
      "   SATURDAYVISIT  SUNDAYVISIT  MORNINGVISIT  DAYVISIT  EVENINGVISIT  \\\n",
      "0             14            0            16         6            24   \n",
      "1              0            0             0         9             0   \n",
      "2              0            0             0         0            15   \n",
      "3              0            6             0         6             0   \n",
      "4              0            0             0         7             0   \n",
      "\n",
      "   NIGHTVISIT  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qizhu\\AppData\\Local\\Temp\\ipykernel_67516\\456656115.py:104: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.fillna(0)\n",
      "C:\\Users\\qizhu\\AppData\\Local\\Temp\\ipykernel_67516\\3867618739.py:221: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X = X.fillna(0)\n",
      "C:\\Users\\qizhu\\AppData\\Local\\Temp\\ipykernel_67516\\3867618739.py:198: RuntimeWarning: invalid value encountered in divide\n",
      "  vals[ix] = (sum_count[0]-y[ix])/(sum_count[1]-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INFO: Data shape \n",
      "  data: torch.Size([1000, 23])\n",
      "  ids: torch.Size([1000])\n",
      "  labels: torch.Size([1000])\n",
      "\n",
      "Sample data from train DataLoader: (tensor([[-1.4534e+00, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.1980e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00,  7.0019e-01, -5.8232e-01,  4.0610e-01,  1.0867e-01,\n",
      "         -3.4145e-01,  1.4728e-01,  2.5418e+00,  4.0947e-01,  2.2970e-01,\n",
      "          1.8235e-02, -1.6827e+00, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "          3.2520e+00, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "          4.2560e-01,  1.8291e+00, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.1980e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.4224e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -2.2489e-01, -5.9607e-02,  4.0610e-01, -1.3282e-01,\n",
      "          3.2938e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.1487e-01, -9.4509e-02, -1.6983e-01,\n",
      "         -2.1552e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [ 4.3703e-01, -2.1591e-01, -5.6623e-01,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5004e-01, -1.7156e-01, -4.2442e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -5.4954e-02, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -1.6210e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.5697e-01,  3.2599e+00,  1.1050e+00,  4.1635e-01,  1.9508e+01,\n",
      "          9.7210e+00,  6.3289e-01, -1.7156e-01,  3.4988e-01,  2.4471e-01,\n",
      "          7.3153e-02, -1.6827e+00,  1.2401e+00, -1.1684e-01,  2.4502e+00,\n",
      "          4.0625e+00,  1.6404e+00,  2.9417e+00,  1.1120e+00,  1.7284e-01,\n",
      "          5.6347e+00,  3.7429e+00, -8.1399e-02],\n",
      "        [ 1.4732e+00, -2.3387e-01, -5.6623e-01,  4.1635e-01, -1.3282e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.4224e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [-1.4534e+00, -1.9795e-01, -9.9966e-01, -3.7267e-01,  2.8173e-02,\n",
      "          1.6710e+00, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -9.4081e-02, -8.9539e-02,\n",
      "         -8.7375e-02, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.4698e-01,\n",
      "         -2.4224e-01, -1.1024e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -1.7100e-01, -5.6623e-01, -2.6122e+00, -5.2322e-02,\n",
      "          3.2938e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02, -1.6827e+00, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01,  1.1285e-02, -1.5617e-01,  5.6303e-02, -7.8448e-02,\n",
      "         -1.3538e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -1.7100e-01,  2.4233e+00,  4.0610e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.4601e-01, -1.8392e-02, -3.1034e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01,  1.7023e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.8530e-02, -2.1231e-01, -8.1399e-02],\n",
      "        [ 2.9700e-01, -2.3387e-01,  2.4888e+00,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -9.4081e-02, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.4698e-01,\n",
      "         -2.4224e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.0791e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -1.8897e-01,  2.4233e+00,  4.0610e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.4831e-01,  8.4056e-02, -3.6318e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "          4.2310e-02, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -8.1957e-02, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -5.6623e-01,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -9.9966e-01, -2.8133e+00, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02]]), tensor([[4249954., 1817422., 1270909.,  500014., 4353410., 2919675.,  214289.,\n",
      "         1649485., 2863222., 1275860.,  544074., 3149090., 2930856., 2083789.,\n",
      "         2146520.]]), tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]))\n",
      "\n",
      "First Row of Data: \n",
      "Features: tensor([[-1.4534e+00, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.1980e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00,  7.0019e-01, -5.8232e-01,  4.0610e-01,  1.0867e-01,\n",
      "         -3.4145e-01,  1.4728e-01,  2.5418e+00,  4.0947e-01,  2.2970e-01,\n",
      "          1.8235e-02, -1.6827e+00, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "          3.2520e+00, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "          4.2560e-01,  1.8291e+00, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.1980e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.4224e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -2.2489e-01, -5.9607e-02,  4.0610e-01, -1.3282e-01,\n",
      "          3.2938e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.1487e-01, -9.4509e-02, -1.6983e-01,\n",
      "         -2.1552e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [ 4.3703e-01, -2.1591e-01, -5.6623e-01,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5004e-01, -1.7156e-01, -4.2442e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -5.4954e-02, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -1.6210e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.5697e-01,  3.2599e+00,  1.1050e+00,  4.1635e-01,  1.9508e+01,\n",
      "          9.7210e+00,  6.3289e-01, -1.7156e-01,  3.4988e-01,  2.4471e-01,\n",
      "          7.3153e-02, -1.6827e+00,  1.2401e+00, -1.1684e-01,  2.4502e+00,\n",
      "          4.0625e+00,  1.6404e+00,  2.9417e+00,  1.1120e+00,  1.7284e-01,\n",
      "          5.6347e+00,  3.7429e+00, -8.1399e-02],\n",
      "        [ 1.4732e+00, -2.3387e-01, -5.6623e-01,  4.1635e-01, -1.3282e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.4224e-01, -1.8679e-01, -8.1399e-02],\n",
      "        [-1.4534e+00, -1.9795e-01, -9.9966e-01, -3.7267e-01,  2.8173e-02,\n",
      "          1.6710e+00, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -9.4081e-02, -8.9539e-02,\n",
      "         -8.7375e-02, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.4698e-01,\n",
      "         -2.4224e-01, -1.1024e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -1.7100e-01, -5.6623e-01, -2.6122e+00, -5.2322e-02,\n",
      "          3.2938e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02, -1.6827e+00, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01,  1.1285e-02, -1.5617e-01,  5.6303e-02, -7.8448e-02,\n",
      "         -1.3538e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -1.7100e-01,  2.4233e+00,  4.0610e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.4601e-01, -1.8392e-02, -3.1034e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01,  1.7023e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.8530e-02, -2.1231e-01, -8.1399e-02],\n",
      "        [ 2.9700e-01, -2.3387e-01,  2.4888e+00,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -9.4081e-02, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.4698e-01,\n",
      "         -2.4224e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -3.6395e-02,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.0791e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [ 1.0392e+00, -1.8897e-01,  2.4233e+00,  4.0610e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.4831e-01,  8.4056e-02, -3.6318e-01,  2.2970e-01,\n",
      "          1.8235e-02,  4.9353e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "          4.2310e-02, -1.4766e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -8.1957e-02, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -5.6623e-01,  4.1635e-01, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02],\n",
      "        [-8.3724e-01, -2.3387e-01, -9.9966e-01, -2.8133e+00, -2.9381e-01,\n",
      "         -3.4145e-01, -1.5038e-01, -1.7156e-01, -4.6645e-01,  2.4471e-01,\n",
      "          7.3153e-02,  5.0213e-01, -1.7886e-01, -1.1684e-01, -1.1656e-01,\n",
      "         -1.5222e-01, -1.0792e-01, -1.5617e-01, -1.4478e-01, -1.6983e-01,\n",
      "         -2.1552e-01, -2.1231e-01, -8.1399e-02]])\n",
      "Bag IDs: tensor([[4249954., 1817422., 1270909.,  500014., 4353410., 2919675.,  214289.,\n",
      "         1649485., 2863222., 1275860.,  544074., 3149090., 2930856., 2083789.,\n",
      "         2146520.]])\n",
      "Labels: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "\n",
      "\n",
      "Feature number: 23\n",
      "\n",
      "-------Model Training Starts -------\n",
      "\n",
      "----- Deep Learn Model Training Starts -----\n",
      "\n",
      "epoch: 10 | loss: 1.119\n",
      "\n",
      "epoch: 20 | loss: 1.115\n",
      "\n",
      "epoch: 30 | loss: 1.111\n",
      "\n",
      "epoch: 40 | loss: 1.106\n",
      "\n",
      "epoch: 50 | loss: 1.100\n",
      "\n",
      "epoch: 60 | loss: 1.094\n",
      "\n",
      "epoch: 70 | loss: 1.088\n",
      "\n",
      "epoch: 80 | loss: 1.081\n",
      "\n",
      "epoch: 90 | loss: 1.073\n",
      "\n",
      "epoch: 100 | loss: 1.066\n",
      "\n",
      "epoch: 110 | loss: 1.059\n",
      "\n",
      "epoch: 120 | loss: 1.051\n",
      "\n",
      "epoch: 130 | loss: 1.044\n",
      "\n",
      "epoch: 140 | loss: 1.037\n",
      "\n",
      "epoch: 150 | loss: 1.030\n",
      "\n",
      "epoch: 160 | loss: 1.023\n",
      "\n",
      "epoch: 170 | loss: 1.017\n",
      "\n",
      "epoch: 180 | loss: 1.011\n",
      "\n",
      "epoch: 190 | loss: 1.005\n",
      "\n",
      "epoch: 200 | loss: 1.000\n",
      "\n",
      "epoch: 210 | loss: 0.995\n",
      "\n",
      "epoch: 220 | loss: 0.990\n",
      "\n",
      "epoch: 230 | loss: 0.985\n",
      "\n",
      "epoch: 240 | loss: 0.980\n",
      "\n",
      "epoch: 250 | loss: 0.976\n",
      "\n",
      "epoch: 260 | loss: 0.972\n",
      "\n",
      "epoch: 270 | loss: 0.968\n",
      "\n",
      "epoch: 280 | loss: 0.965\n",
      "\n",
      "epoch: 290 | loss: 0.961\n",
      "\n",
      "epoch: 300 | loss: 0.958\n",
      "\n",
      "Testing starts here.......\n",
      "\n",
      " Model testing on Training Data\n",
      "\n",
      "Accuracy: 84.2 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[462  69]\n",
      " [ 57 207]]\n",
      "\n",
      "Testing area for sample input data\n",
      "\n",
      "Data shape: torch.Size([15, 23])\n",
      "\n",
      "Number of training features: 23\n",
      "\n",
      "Bagids shape: torch.Size([1, 15])\n",
      "\n",
      "Construct data_df\n",
      "\n",
      "Construct bagids_df\n",
      "\n",
      "bagids_df shape is (15, 1).\n",
      "data_df shape is (15, 23).\n",
      "bagids_df column is Index(['MODEL_ID'], dtype='object').\n",
      "data_df column is Index(['ADVERTISER_ID', 'TOTAL_CLICK', 'DEVICE', 'BROWSER',\n",
      "       'UNIQUE_SESSION_NUM', 'UNIQUE_DAYS', 'TOTAL_TIME_ONSITE', 'TOTAL_SPEND',\n",
      "       'AVG_SESSION_DURATION', 'REFERRAL_SOURCE', 'SITE_INTERACTION',\n",
      "       'REFERRAL_SITE', 'MONDAYVISIT', 'TUESDAYVISIT', 'WEDNESDAYVISIT',\n",
      "       'THURSDAYVISIT', 'FRIDAYVISIT', 'SATURDAYVISIT', 'SUNDAYVISIT',\n",
      "       'MORNINGVISIT', 'DAYVISIT', 'EVENINGVISIT', 'NIGHTVISIT'],\n",
      "      dtype='object').\n",
      "\n",
      "---------------a--------------------\n",
      "\n",
      "---------------d--------------------\n",
      "\n",
      "->Explain_with_shap Error: tuple index out of range\n",
      "None\n",
      "\n",
      " Model testing on Testing Data\n",
      "\n",
      "Accuracy: 82.1 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  22]\n",
      " [ 13  52]]\n",
      "\n",
      "Testing area for sample input data\n",
      "\n",
      "Data shape: torch.Size([15, 23])\n",
      "\n",
      "Number of training features: 23\n",
      "\n",
      "Bagids shape: torch.Size([1, 15])\n",
      "\n",
      "Construct data_df\n",
      "\n",
      "Construct bagids_df\n",
      "\n",
      "bagids_df shape is (15, 1).\n",
      "data_df shape is (15, 23).\n",
      "bagids_df column is Index(['MODEL_ID'], dtype='object').\n",
      "data_df column is Index(['ADVERTISER_ID', 'TOTAL_CLICK', 'DEVICE', 'BROWSER',\n",
      "       'UNIQUE_SESSION_NUM', 'UNIQUE_DAYS', 'TOTAL_TIME_ONSITE', 'TOTAL_SPEND',\n",
      "       'AVG_SESSION_DURATION', 'REFERRAL_SOURCE', 'SITE_INTERACTION',\n",
      "       'REFERRAL_SITE', 'MONDAYVISIT', 'TUESDAYVISIT', 'WEDNESDAYVISIT',\n",
      "       'THURSDAYVISIT', 'FRIDAYVISIT', 'SATURDAYVISIT', 'SUNDAYVISIT',\n",
      "       'MORNINGVISIT', 'DAYVISIT', 'EVENINGVISIT', 'NIGHTVISIT'],\n",
      "      dtype='object').\n",
      "\n",
      "---------------a--------------------\n",
      "\n",
      "---------------d--------------------\n",
      "\n",
      "->Explain_with_shap Error: tuple index out of range\n",
      "None\n",
      "\n",
      "Testing ends here.......\n",
      "\n",
      "Run time for training model is: 55.11553192138672 seconds\n",
      "\n",
      "-------Model Training Ends -------\n",
      "\n",
      "Start loading audience for prediction.\n",
      "\\Error: name 'prediction_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "    training_ratio = 2\n",
    "    model_training = True\n",
    "    if_store_model = False\n",
    "    model_prediction = True\n",
    "    AUDIENCE_LIMIT = 1000\n",
    "    # Model setting\n",
    "    n_neurons = 5\n",
    "    lr = 1e-4\n",
    "    n_epochs = 300\n",
    "    batch_size = 15\n",
    "    weight_decay = 0.0001\n",
    "    \n",
    "    # Initialize LOOKALIKE_MODEL class correctly\n",
    "    lookalike_model = LOOKALIKE_MODEL(\n",
    "        training_ratio = training_ratio,   # 1-10 \n",
    "        model_training = model_training,  \n",
    "        if_store_model = if_store_model,   \n",
    "        model_prediction = model_prediction,\n",
    "        AUDIENCE_LIMIT = AUDIENCE_LIMIT,\n",
    "        n_neurons = n_neurons,\n",
    "        lr = lr,\n",
    "        n_epochs = n_epochs,\n",
    "        batch_size = batch_size,\n",
    "        weight_decay = weight_decay\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # Call the main method of LOOKALIKE_MODEL and get the response\n",
    "    LOOKALIKE_MODEL_response = lookalike_model.main()\n",
    "    \n",
    "    LOOKALIKE_MODEL_response \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
